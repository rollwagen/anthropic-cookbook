{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tool use supports a parameter called `tool_choice` that allows you to specify how you want Claude to call tools. In this notebook, we'll take a look at how it works and when to use it. Before going any further, make sure you are comfortable with the basics of tool use with Claude.\n",
    "\n",
    "When working with the `tool_choice` parameter, we have three possible options: \n",
    "\n",
    "* `auto` allows Claude to decide whether to call any provided tools or not\n",
    "* `tool` allows us to force Claude to always use a particular tool\n",
    "* `any` tells Claude that it must use one of the provided tools, but doesn't force a particular tool\n",
    "\n",
    "Let's take a look at each option in detail. We'll start by importing the Anthropic SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "# \"anthropic.claude-3-haiku-20240307-v1:0\"  \"anthropic.claude-3-sonnet-20240229-v1:0\"  \"anthropic.claude-3-opus-20240229-v1:0\"\n",
    "MODEL_ID = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "region_name= os.getenv(\"AWS_REGION\", default=\"us-west-2\")\n",
    "bedrock_client = boto3.client(service_name='bedrock-runtime', region_name=region_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto\n",
    "\n",
    "Setting `tool_choice` to `auto` allows the model to automatically decide whether to use tools or not.  This is the default behavior when working with tools. \n",
    "\n",
    "To demonstrate this, we're going to provide Claude with a fake web search tool. We will ask Claude questions, some of which would require calling the web search tool and other which Claude should be able to answer on its own.\n",
    "\n",
    "Let's start by defining a tool called `web_search`.  Please note, to keep this demo simple, we're not actually searching the web here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(topic):\n",
    "    print(f\"pretending to search the web for {topic}\")\n",
    "\n",
    "web_search_tool = {\n",
    "    \"name\": \"web_search\",\n",
    "    \"description\": \"A tool to retrieve up to date information on a given topic by searching the web\",\n",
    "    \"inputSchema\": {\n",
    "        \"json\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to search the web for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }\n",
    "    }\n",
    "}  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a function that accepts a user_query and passes it along to Claude, along with the `web_search_tool`. \n",
    "\n",
    "We also set `tool_choice` to `auto`:\n",
    "\n",
    "```py\n",
    "tool_choice={\"type\": \"auto\"}\n",
    "```\n",
    "\n",
    "Here's the complete function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "def chat_with_web_search(user_query):\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"text\": user_query}]}]\n",
    "\n",
    "    system_prompt=f\"\"\"\n",
    "    Answer as many questions as you can using your existing knowledge.  \n",
    "    Only search the web for queries that you can not confidently answer.\n",
    "    Today's date is {date.today().strftime(\"%B %d %Y\")}\n",
    "    If you think a user's question involves something in the future that hasn't happened yet, use the search tool.\n",
    "    \"\"\"\n",
    "\n",
    "    converse_response = bedrock_client.converse(\n",
    "        system=[{\"text\" : system_prompt}],\n",
    "        modelId=MODEL_ID,\n",
    "        messages = messages,\n",
    "        inferenceConfig = {\"maxTokens\": 4096},\n",
    "        toolConfig = {\n",
    "             'tools': [\n",
    "                {\n",
    "                    'toolSpec': web_search_tool\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    last_content_block = converse_response['output']['message']['content'][-1]\n",
    "    if last_content_block.get(\"text\"):\n",
    "        print(\"Claude did NOT call a tool\")\n",
    "        print(f\"Assistant: {last_content_block['text']}\")\n",
    "    elif last_content_block.get(\"toolUse\"):\n",
    "        print(\"Claude wants to use a tool\")\n",
    "        print(last_content_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a question Claude should be able to answer without using the tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude did NOT call a tool\n",
      "Assistant: The sky appears blue during the daytime. This is because of the way sunlight interacts with the gases in the Earth's atmosphere. The blue color of the sky is caused by the scattering of sunlight by the gas molecules in the atmosphere.\n"
     ]
    }
   ],
   "source": [
    "chat_with_web_search(\"What color is the sky?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we ask \"What color is the sky?\", Claude does not use the tool.  Let's try asking something that Claude should use the web search tool to answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude wants to use a tool\n",
      "{'toolUse': {'toolUseId': 'tooluse_3Re2lk8AR1q9dZkBWiFq3Q', 'name': 'web_search', 'input': {'topic': '2024 miami grand prix winner'}}}\n"
     ]
    }
   ],
   "source": [
    "chat_with_web_search(\"Who won the 2024 Miami Grand Prix?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we ask \"Who won the 2024 Miami Grand Prix?\", Claude uses the web search tool! \n",
    "\n",
    "Let's try a few more examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude did NOT call a tool\n",
      "Assistant: The Los Angeles Rams won Super Bowl LVI in 2022, defeating the Cincinnati Bengals by a score of 23-20. The game was played on February 13, 2022 at SoFi Stadium in Inglewood, California.\n"
     ]
    }
   ],
   "source": [
    "# Claude should NOT need to use the tool for this:\n",
    "chat_with_web_search(\"Who won the superbowl in 2022?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude wants to use a tool\n",
      "{'toolUse': {'toolUseId': 'tooluse_-9JRnkcBTxy5fGyzhKPmlQ', 'name': 'web_search', 'input': {'topic': '2024 super bowl winner'}}}\n"
     ]
    }
   ],
   "source": [
    "# Claude SHOULD use the tool for this:\n",
    "chat_with_web_search(\"Who won the superbowl in 2024?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Prompt Matters!\n",
    "\n",
    "When working with `tool_choice` of `auto`, it's important that you spend time to write a detailed prompt.  Often, Claude can be over-eager to call tools.  Writing a detailed prompt helps Claude determine when to call a tool and when not to.  In the above example, we included specific instructions in the system prompt: \n",
    "\n",
    "\n",
    "```py\n",
    " system_prompt=f\"\"\"\n",
    "    Answer as many questions as you can using your existing knowledge.  \n",
    "    Only search the web for queries that you can not confidently answer.\n",
    "    Today's date is {date.today().strftime(\"%B %d %Y\")}\n",
    "    If you think a user's question involves something in the future that hasn't happened yet, use the search tool.\n",
    "\"\"\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forcing a specific tool\n",
    "\n",
    "We can force Claude to use a particular tool using `tool_choice`.  In the example below, we've defined two simple tools: \n",
    "* `print_sentiment_scores` - a tool that \"tricks\" Claude into generating well-structured JSON output containing sentiment analysis data.  For more info on this approach, see [Extracting Structured JSON using Claude and Tool Use](https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/extracting_structured_json.ipynb)\n",
    "* `calculator` - a very simple calculator tool that takes two numbers and adds them together \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"print_sentiment_scores\",\n",
    "            \"description\": \"Prints the sentiment scores of a given tweet or piece of text.\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"positive_score\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"The positive sentiment score, ranging from 0.0 to 1.0.\"\n",
    "                        },\n",
    "                        \"negative_score\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"The negative sentiment score, ranging from 0.0 to 1.0.\"\n",
    "                        },\n",
    "                        \"neutral_score\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"The neutral sentiment score, ranging from 0.0 to 1.0.\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"positive_score\", \"negative_score\", \"neutral_score\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"calculator\",\n",
    "            \"description\": \"Adds two numbers\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"num1\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"first number to add\"\n",
    "                        },\n",
    "                        \"num2\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"second number to add\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"num1\", \"num2\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to write a function called `analyze_tweet_sentiment` that takes a tweet and prints a basic sentiment analysis of that tweet.  Eventually we will \"force\" Claude to use our sentiment analysis tool, but we'll start by showing what happens when we **do not** force the tool use. \n",
    "\n",
    "In this first \"bad\" version of the `analyze_tweet_sentiment` function, we provide Claude with both tools. For the sake of comparison, we'll start by setting tool_choice to \"auto\":\n",
    "\n",
    "```py\n",
    "tool_choice={\"type\": \"auto\"}\n",
    "```\n",
    "\n",
    "Please note that we are deliberately not providing Claude with a well-written prompt, to make it easier to see the impact of forcing the use of a particular tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_tweet_sentiment(query):\n",
    "    converse_response = bedrock_client.converse(\n",
    "        modelId=MODEL_ID,\n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": query}]\n",
    "        }],\n",
    "        inferenceConfig = {\"maxTokens\": 4096},\n",
    "        toolConfig = {\n",
    "            'tools': [\n",
    "                {\n",
    "                    'toolSpec': web_search_tool\n",
    "                }\n",
    "            ],\n",
    "            \"toolChoice\": { 'auto': {} },\n",
    "        }\n",
    "    )\n",
    "    print(converse_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we call the function with the tweet \"Holy cow, I just made the most incredible meal!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'b3a550b9-db96-4c6c-832d-1e07a0a91ab4', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 11 Jun 2024 11:42:20 GMT', 'content-type': 'application/json', 'content-length': '405', 'connection': 'keep-alive', 'x-amzn-requestid': 'b3a550b9-db96-4c6c-832d-1e07a0a91ab4'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': \"That's great to hear! I'd love to hear more about the amazing meal you prepared. What did you make? I'm always eager to learn about new recipes and culinary creations from humans. Please tell me all the delicious details!\"}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 253, 'outputTokens': 53, 'totalTokens': 306}, 'metrics': {'latencyMs': 3652}}\n"
     ]
    }
   ],
   "source": [
    "analyze_tweet_sentiment(\"Holy cow, I just made the most incredible meal!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude does not call our sentiment analysis tool:\n",
    "> \"That's great to hear! I don't actually have the capability to assess sentiment from text, but it sounds like you're really excited and proud of the incredible meal you made\n",
    "\n",
    "Next, let's imagine someone tweets this: \"I love my cats! I had four and just adopted 2 more! Guess how many I have now?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'aeac3058-e422-4f29-bd97-40e651b4b90b', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 11 Jun 2024 11:44:59 GMT', 'content-type': 'application/json', 'content-length': '522', 'connection': 'keep-alive', 'x-amzn-requestid': 'aeac3058-e422-4f29-bd97-40e651b4b90b'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': \"Okay, let's break this down step-by-step:\\n* You originally had 4 cats\\n* You just adopted 2 more cats\\n* To get the new total, we take the original number and add the number of new cats adopted:\"}, {'toolUse': {'toolUseId': 'tooluse_g8l_dIXGS7K13AcX9PJ0cw', 'name': 'math_arithmetic', 'input': {'operation': 'add', 'operand1': '4', 'operand2': '2'}}}]}}, 'stopReason': 'tool_use', 'usage': {'inputTokens': 265, 'outputTokens': 147, 'totalTokens': 412}, 'metrics': {'latencyMs': 7651}}\n"
     ]
    }
   ],
   "source": [
    "analyze_tweet_sentiment(\"I love my cats! I had four and just adopted 2 more! Figure how many I have now?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude wants to call the calculator tool:\n",
    "\n",
    "> ToolUseBlock(id='toolu_staging_01RFker5oMQoY6jErz5prmZg', input={'num1': 4, 'num2': 2}, name='calculator', type='tool_use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, this current implementation is not doing what we want (mostly because we set it up to fail). \n",
    "\n",
    "Next, let's force Claude to **always** use the `print_sentiment_scores` tool by updating `tool_choice`:\n",
    "\n",
    "```py\n",
    "tool_choice={\"type\": \"tool\", \"name\": \"print_sentiment_scores\"}\n",
    "```\n",
    "\n",
    "In addition to setting `type` to `tool`, we must provide a particular tool name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_tweet_sentiment(query):\n",
    "    converse_response = bedrock_client.converse(\n",
    "        modelId=MODEL_ID,\n",
    "        inferenceConfig={\"maxTokens\": 4096},\n",
    "        messages=[{\n",
    "             \"role\": \"user\",\n",
    "                \"content\": [{\"text\": query}]\n",
    "        }],\n",
    "        toolConfig = {\n",
    "                'tools': tools,\n",
    "                \"toolChoice\": {\n",
    "                    'tool': {'name': 'print_sentiment_scores'}\n",
    "                },\n",
    "        }\n",
    "    )\n",
    "    print(converse_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we try prompting Claude with the same prompts from earlier, it's always going to call the `print_sentiment_scores` tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '00c46900-f8f3-4e55-95ec-9409937a413e', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 11 Jun 2024 11:45:13 GMT', 'content-type': 'application/json', 'content-length': '335', 'connection': 'keep-alive', 'x-amzn-requestid': '00c46900-f8f3-4e55-95ec-9409937a413e'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'toolUse': {'toolUseId': 'tooluse_iCfAEUoqREu18__8Uqz_6Q', 'name': 'print_sentiment_scores', 'input': {'positive_score': 0.9, 'negative_score': 0.1, 'neutral_score': 0.0}}}]}}, 'stopReason': 'tool_use', 'usage': {'inputTokens': 527, 'outputTokens': 79, 'totalTokens': 606}, 'metrics': {'latencyMs': 1115}}\n"
     ]
    }
   ],
   "source": [
    "analyze_tweet_sentiment(\"Holy cow, I just made the most incredible meal!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude calls our `print_sentiment_scores` tool:\n",
    "\n",
    "> ToolUseBlock(id='toolu_staging_01FMRQ9pZniZqFUGQwTcFU4N', input={'positive_score': 0.9, 'negative_score': 0.0, 'neutral_score': 0.1}, name='print_sentiment_scores', type='tool_use')\n",
    "\n",
    "Even if we try to trip up Claude with a \"Math-y\" tweet, it still always calls the `print_sentiment_scores` tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '8769b55d-cee1-4fb8-a253-743330c0867f', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Tue, 11 Jun 2024 11:45:29 GMT', 'content-type': 'application/json', 'content-length': '335', 'connection': 'keep-alive', 'x-amzn-requestid': '8769b55d-cee1-4fb8-a253-743330c0867f'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'toolUse': {'toolUseId': 'tooluse_kgl6IMeeTsG6ofCpmYpiHQ', 'name': 'print_sentiment_scores', 'input': {'positive_score': 0.9, 'negative_score': 0.0, 'neutral_score': 0.1}}}]}}, 'stopReason': 'tool_use', 'usage': {'inputTokens': 540, 'outputTokens': 79, 'totalTokens': 619}, 'metrics': {'latencyMs': 1643}}\n"
     ]
    }
   ],
   "source": [
    "analyze_tweet_sentiment(\"I love my cats! I had four and just adopted 2 more! Guess how many I have now?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we're forcing Claude to call our `print_sentiment_scores` tool, we should still employ some basic prompt engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_tweet_sentiment(query):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the sentiment in the following tweet: \n",
    "    <tweet>{query}</tweet>\n",
    "    \"\"\"\n",
    "    \n",
    "    converse_response = bedrock_client.converse(\n",
    "            modelId=MODEL_ID,\n",
    "            inferenceConfig={\"maxTokens\": 4096},\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"text\": prompt}]\n",
    "            }],\n",
    "            toolConfig = {\n",
    "                'tools': tools,\n",
    "                \"toolChoice\": { 'auto': {} },\n",
    "            }\n",
    "    )\n",
    "    print(converse_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Any\n",
    "\n",
    "The final option for `tool_choice` is `any` which allows us to tell Claude \"you must call a tool, but you can pick which one\".  Imagine we want to create a SMS chatbot using Claude.  The only way for this chatbot to actually \"communicate\" with a user is via SMS text message. \n",
    "\n",
    "In the example below, we make a very simple text-messaging assistant that has access to two tools:\n",
    "* `send_text_to_user` sends a text message to a user\n",
    "* `get_customer_info` looks up customer data based on a username\n",
    "\n",
    "The idea is to create a chatbot that always calls one of these tools and never responds with a non-tool response.  In all situations, Claude should either respond back by trying to send a text message or calling `get_customer_info` to get more customer information.\n",
    "\n",
    "Most importantly, we set `tool_choice` to \"any\":\n",
    "\n",
    "```py\n",
    "tool_choice={\"type\": \"any\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_text_to_user(text):\n",
    "    # Sends a text to the user\n",
    "    # We'll just print out the text to keep things simple:\n",
    "    print(f\"TEXT MESSAGE SENT: {text}\")\n",
    "\n",
    "def get_customer_info(username):\n",
    "    return {\n",
    "        \"username\": username,\n",
    "        \"email\": f\"{username}@email.com\",\n",
    "        \"purchases\": [\n",
    "            {\"id\": 1, \"product\": \"computer mouse\"},\n",
    "            {\"id\": 2, \"product\": \"screen protector\"},\n",
    "            {\"id\": 3, \"product\": \"usb charging cable\"},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"send_text_to_user\",\n",
    "            \"description\": \"Sends a text message to a user\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"text\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The piece of text to be sent to the user via text message\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"text\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"get_customer_info\",\n",
    "            \"description\": \"gets information on a customer based on the customer's username.  Response includes email, username, and previous purchases. Only call this tool once a user has provided you with their username\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"username\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The username of the user in question. \"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"username\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "All your communication with a user is done via text message.\n",
    "Only call tools when you have enough information to accurately call them.  \n",
    "Do not call the get_customer_info tool until a user has provided you with their username. This is important.\n",
    "If you do not know a user's username, simply ask a user for their username.\n",
    "\"\"\"\n",
    "\n",
    "def sms_chatbot(user_message):\n",
    "    # messages = [{\"role\": \"user\", \"content\":user_message}]\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": user_message}]\n",
    "    }]\n",
    "\n",
    "    converse_response = bedrock_client.converse(\n",
    "            modelId=MODEL_ID,\n",
    "            inferenceConfig={\"maxTokens\": 4096},\n",
    "            system=[{\"text\" : system_prompt}],\n",
    "            messages=messages,\n",
    "            toolConfig = {\n",
    "                'tools': tools,\n",
    "                \"toolChoice\": { 'any': {} },\n",
    "            }\n",
    "    )\n",
    "\n",
    "    print(f\"stopReason={converse_response['stopReason']}\")\n",
    "    if converse_response['stopReason'] == \"tool_use\":\n",
    "        last_content_block = converse_response['output']['message']['content'][-1]\n",
    "        if last_content_block.get(\"toolUse\"):\n",
    "            tool_name = last_content_block.get(\"toolUse\").get('name')\n",
    "            tool_inputs = last_content_block.get(\"toolUse\").get('input')\n",
    "            print(f\"=======Claude Wants To Call The {tool_name} Tool=======\")\n",
    "            if tool_name == \"send_text_to_user\":\n",
    "                send_text_to_user(tool_inputs[\"text\"])\n",
    "            elif tool_name == \"get_customer_info\":\n",
    "                print(get_customer_info(tool_inputs[\"username\"]))\n",
    "            else:\n",
    "                print(\"Oh dear, that tool doesn't exist!\")\n",
    "            \n",
    "    else:\n",
    "        print(\"No tool was called. This shouldn't happen!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopReason=tool_use\n",
      "=======Claude Wants To Call The send_text_to_user Tool=======\n",
      "TEXT MESSAGE SENT: Hello! I'm an AI assistant. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "sms_chatbot(\"Hey there! How are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude responds back by calling the `send_text_to_user` tool.\n",
    "\n",
    "Next, we'll ask Claude something a bit trickier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopReason=tool_use\n",
      "=======Claude Wants To Call The send_text_to_user Tool=======\n",
      "TEXT MESSAGE SENT: Hello, I'd be happy to look up information on your order. Could you please provide me with your username? I'll need that to access your account details and order history.\n"
     ]
    }
   ],
   "source": [
    "sms_chatbot(\"I need help looking up an order\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude wants to send a text message, asking a user to provide their username.\n",
    "\n",
    "Now, let's see what happens when we provide Claude with our username:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopReason=tool_use\n",
      "=======Claude Wants To Call The get_customer_info Tool=======\n",
      "{'username': 'jenny76', 'email': 'jenny76@email.com', 'purchases': [{'id': 1, 'product': 'computer mouse'}, {'id': 2, 'product': 'screen protector'}, {'id': 3, 'product': 'usb charging cable'}]}\n"
     ]
    }
   ],
   "source": [
    "sms_chatbot(\"I need help looking up an order.  My username is jenny76\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claude calls the `get_customer_info` tool, just as we hoped! \n",
    "\n",
    "Even if we send Claude a gibberish message, it will still call one of our tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopReason=tool_use\n",
      "=======Claude Wants To Call The send_text_to_user Tool=======\n",
      "TEXT MESSAGE SENT: I'm sorry, I didn't understand your request. Could you please rephrase what you need help with? I'll do my best to assist you.\n"
     ]
    }
   ],
   "source": [
    "sms_chatbot(\"askdj aksjdh asjkdbhas kjdhas 1+1 ajsdh\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
